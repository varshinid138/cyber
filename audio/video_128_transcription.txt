 Hi everyone, in this video we will be looking into artificial neural network. So let's hop into it. Artificial neural networks are simply, we call this as A and N. Artificial neural networks. So the concept of artificial neural networks has been taken out from humans. Like if you are a background of biology student, you might have seen that basically how a neuron looks like. Yeah, neuron, neuron which is present in human brain, what he does, he passes information. He passes information from one unit to other neuron such as he might have heard about the reaction in stimulus that how do you know that the iron is hot. How do you know that the rose plant got thorns in it. So it may harm you. So kind of like that, how does it works? So basically your neurons are trained upon it. But if you touch a hot iron, you are going to get harmed. Similarly, similarly in your artificial neural networks, we got neurons. So let me just show it to you how it looks like if you ever encountered. It's kind of look like a pre-lex structure. It just comes like this. Not like this. It won't happen. So it kind of follows. Similar structure not exactly, not kind of drawn very perfectly, but similar to this, it has a neuron basically. It has something that's real like this, which goes in this particular manner. You might have seen anywhere. You might have seen in your high school these type of structures. And for sure. So basically the work of neuron is to kind of understand things to give you to give a possibility like what are you humans. So without neurons, you won't be a human. We won't be an intelligent being. So you won't be an intelligent being. So because of the neuron we have in our body or in our basic mind, we know as an intelligent being same thing, same thing. We also got neurons basically, these are known as artificial neurons, which are present in your machine learning. Okay. So remember that this center part is somewhat called as nucleus. These branches are known as a dendrite. And like this, like this particles, or not to physical particles, like this neurons around in our body, we got 31 billion neurons, 31 billion neurons. Now each neuron has a certain thing to do, it transfer messages. It transfer messages is transfer understanding. It transfers basically to your conscience, this and all the things. So similarly, similarly in your machine learning, we got we got single led neural network. We got single led neural network. So in here, what happens? You will be having your features. You will be having your features passed into each one one neuron. Like you have seen, what happens? The data will be coming, not basically the data. Let's say when you touch on, or die, what happens? The data from your finger will be passing through your neuron and it will go into your head to get a reaction. Should I touch it further? Should I remove what you have? So same thing here also, I will just make sure you do. You draw this. Okay. Fine. So let's say I'm drawing three circles here. So each circle represent one one features, one one features from this features. Let me do it for that. I will explain to you. You can see the difference between the two. So let's take an example. Let's take one example here. In this example, let's say you got around four columns. Let's say you got age column of a particular person. You got weight of the particular person. You got basically three things. And based on the three things, you are going to predict that if the person is going to have diabetes or not. And for certain things, you got values also like this. Lots of values you got for each for weight for height for diabetes also. Okay. So what you will do, you will pass your features to your artificial neurons. These are your input layer or the artificial layer. Okay. Basically, you will have a lot of values. So let's see the artificial layer. Okay. Basically, what we call as we call this as a concept from. We call this as a concept from or a artificial. So let me just write it out. So by here. And artificial. Neural. Okay. We are going to pass this age in here. So for each for each column, you got you are going to create one one artificial neural. So here this age will be your X one, where it will be your X two, height will be your X three. And of course, the result being diabetes or not will be getting from your output layer. So how does this entire chain works? So this is your just single layer neural network. You can see only this is only one neuron present inside it. But there are chances that it will be multiple layers. I will show you how complex or test neural networks looks like. So for the time being, let's go through this. So we understand that. Age, weight height, which are the three columns of a data set will be passed with a three attention neurons. And here with these three artificial neurons, what it will do, it will take your data. It will take your data by updating weights. By updating. Which and it is going to pass it to your. Hidden layer. It's going to pass it to your. Hidden layer. So what happens in your hidden layer then what happens in your hidden layer. So in a hidden layer, basically two things happens. Let me just do one thing. Start there. So in a hidden layer, basically two things happen. What are the two things that you start it out? Two things or dark things happen so that you won't forget. Okay, the first of all, first of all, what will happen? They calculate the summation of your X i w of i plus your bias, which is your weight, a patient formula. So here what we are doing. If you just write the formula in here, so first thing. It's summation of X of i w of i plus your bias. Okay, so now you got X of 1. You have got w of 1. Now you will be thinking what is w of 1 then? So let's say this w of 1 is weight just a random value. A random value at first. So when your data get passed here, a random weight value is getting generated. After it get generated, it goes to the hidden layer like this. Well, I have created one star. So what happens in the star as I told you summation of X of i multiplied with w of i as X of i is not just single data. It consists of multiple data points also. So X of i plus w of i will be getting stored here and and a random bias will be generated also random bias will be generated. This is how it works. Then what happened? Then here it is going to give you a certain output. This star is going to give you a certain output. So let's say the output is over. The output is over. Okay. Okay. Is output on output? Yeah, it is going to give you two outputs. See this. Here it is going to give you one output. One output. All set is going to give you one weight. Again, one weight will be generated here. So again, what will happen again this as I told you it's going to generate one output. That means that means that it will be second thing also happening as we are going with a classification task. That is the person is having a diabetes or not. The person is having diabetes or not. So what it will do is going to create an activation function. Now, I will explain you what this activation function means. Activation function. Let me just try to clear out. We'll get an activation function. So here the activation function is going to be your sig model function. Because you I think you have heard about the sig model function. That if you passed the data if your data will be coming in a continuous number. If the data is greater than 0.5, it is going to be treated as one. If your data is less than 0.5, it will be treated as zero. So this one. Sigma model. Activation function. Let me just draw it out. So what was one upon one plus e to the power minus x and instead of x. What we have taken one plus e to the power minus w transpose x plus b. We have seen this earlier. Don't don't go into that. So let's see this how it was done. Basically you will get a zero value here and you will get your one value here. And a sig model functions like kind of a shaped curve like this. It kind of follows a curve like this not exactly a branded curve. Let me just do it once again. We are kind of like this. So where this is your threshold value 0.5. That means the data points which are lying less than 0.5 will be treated as zero. The data point which are lying greater than 0.5 will be treated as one. So here after after it gets an output. Let's output one after passing through the activation function. Then it's again get added with a new weight here, which is lying in this line. So after that again it passes through the activation function again. It passes through the. Activation function and you get your final output. Or let's say I'm just writing your final output. Final. So let's see this again. How it happens? First we are going to give up features X of i. So here the data is going to get passed and our random weight is going to get generated. So random are not just weight random weight and random bias also gets generated here. It will go down till here. And what will happen here? Only two things will happen. One is summation of X of i plus W of i plus 5. So let me just do it somewhere here.