 Hello everyone. So in this video, let's see how we can address the detection of malicious URLs as a multi-class classification problem. So what we'll do is we'll classify the raw URLs. So in this video, we'll classify the raw URLs into different class types such as benign, regression, malware, or decrysmit. So as we know that machine learning algorithms only support numerical inputs. So we'll create lexical numerical features from the input URLs. So what we'll do will convert the input URLs and we'll extract lexical numeric features. From this URL, rather than passing the actual raw URL. So if you don't know about the cyclical features, it's quite simple, where it is extracting the important character's takes of this URL. Then after that, we'll just implement some of the popular machine learning and symbol classifiers such as random forest and execute. Then later we'll compare the performance and we'll just select the best model for our prediction. So coming to the data set we are using. So in this case, we'll be using this malicious URL data set which contains 6,000, 51,000 URLs out of which 4,000 like are benign or safe URLs and 96,000 are decrysmit and 94,000 are phishing URLs as well as 32,000 malware URLs. So now let's discuss the different types of URLs in our data set. So as I said, the first one is your benign URLs. So benign URLs, so these are nothing but your safe or we can just say safe to browse URLs. So some of the examples are the popular one Google.com, myspace.com, infinity sw.com. So these are some of the same URLs and the second one, malware URLs. So these are the type of URLs which inject malware into the victim system. So these inject malware into the victim system. So once you are seeing or the victim, once you visit such URL, some of the files will be automatically downloaded. So some of the malware URLs are right here. So here this contains your IP address and here there will be some suspicious names, something like that. Then the third one is your de-pacement URL. This is the third one. So de-pacement URLs are generally created by hackers with the intention of breaking into web server. So these are created to break into the web server. And what they'll do is after they break in, they'll replace the post website with one of their own. They'll replace the post website. So using techniques such as code injection or cross site scripting, what they'll do is they'll just replace the URLs such as religious websites or government websites, bank websites and corporate websites. And they'll just demand their answer. So some of the popular de-pacement URLs, the third one, approvy.com, Juven C, RAC IT. So these are some of the de-pacement URLs and the fourth one, phishing URLs. So by creating this phishing URLs, hackers want they'll do, they'll try to steal the sensitive, personal or financial information. Also phishing has the name settings. They'll try to steal sensitive information, sensitive information like your personal information, financial information or login credentials, credit card numbers, internet banking details, etc. Now, okay. So next, we'll see how we can classify or detect malicious URLs. So here, I'm just importing the libraries. We'll import all the necessary Python libraries we'll be using in this project. So next, just writing all the warmings. I'm just reading this data set. So in this step, we will import the data set using Pandas library and just check the sample of the data. Yeah. So this is the sample of the data, which contains three columns. First one is the URL, second one is the type. So from the above, output, we can see that the data set has six lakh, 51,191 records, with two columns URL and the type of the URL. So next, we'll move towards picture engineering part, which will create lexical pictures from raw URLs. And if I check out the type, so type is my target, which is having the four categories, benign, detachment, fishing and malware. So now let's look into picture engineering. So in the feature engineering step, we'll extract the following lexical features. Having IP address, then we'll extract the lexical features from the URLs, because all these features will be used as an input features for training my machine learning model. So the first one, having IP address. So this is the first picture I'm extracting from the URL. So generally cyber attack is using IP address in the place of domain name to hide the identity of the website. So this feature will check whether the URL has IP address or not. Second one, abnormal URL. So this feature, it can be extracted from the who is database. So for legitimate website, identity is a typical part of it URL. So this function in just checks if that URL is present in the who is database, if it is there, if it is matching it will return one, otherwise it will return zero. Then Google search index or Google index. So in this picture, we'll check whether the URL is indexed in the Google search console or not. If it is there, it will return one as it will return zero. Then count. So count of dot. See, sometimes the phishing or malware websites, they'll use more than two subdomains in the URL. So each subdomain is separated by a dot. So any URL contains more than three dots, then it will increase the probability of malicious site. So I'm just taking that. So this function, what it does, it just returns the number of dots in the URL. So URL dot. Dot return the count of dot. Then we have some more features, count of www. So generally, most of the same websites, most of the same website, they'll have one www. So this feature, it'll just help in detecting malicious website. If the URL has more than one, or www, in it, then we're also counting the number of 100% at the rate. So the presence of other rates in your URL, ignores everything previously to it. And the count of directly, the presence of multiple directries in your URL generally indicates suspicious path. For example, if we look into this, see how many directries are there. We have multiple directries in this example. So it'll just increase the chances of that being malware. So in the similar manner, I'm just extracting all the features, important features. So we saw that tell count directly, then count the embedded domain. So the number of embedded domains can be helpful in detecting the malicious URLs. It can be done by checking the currents of double forward slash. In the URL. Then suspicious words can also be used. Then we are counting the HTTPs. So count HTTPs generally malicious URLs. Do not use HTTPs protocols because it's generally required some credentials and ensures that the website is safe for the transaction. So in the presence of, so the presence or absence of HTTPs protocol near L is important for the user to be able to use the app. So like that, I'm just, I'm just extracting multiple things. For example, just a few, just a name if you have them URL length. So attackers generally use a long URL to hide the domain name. So if we found an average, for a safe URL, the average length of is almost 7.4. So if the length of URL is very high, the probability will be probably being a malware and it will be quite high. Then, count letters, count digit. So count letters, the number of letters in the URLs also plays significant role in identifying malicious URLs because attackers they'll try to increase the length of the URL to either domain name as I said. And it's generally done by increasing the number of letters and digits in the URL. So I'm just counting the number of letters and the number of digits. So let me run all the functions. So I just given a brief of the lexical features. Okay. Well, now let's look into the second part, your visualization part. Okay, before that, let's look at the final data, how it looks like. Let's wait for a minute. You So in the next step, we'll change the distribution of different features for all our four classes of the URL. So after we extract all the features, this is how my data set looks like. So count of W, count of dot, count of W, W, count of what, number of direct trees, count of embedded timing, embedded domains. So this is how my data looks like. Okay, now let's get into a EDA part. So the first one, I'm just visualizing a count plot for the use of IP. So if you observe from the distribution of this use of IP, the exact site it contains the four categories. And now we will look at some sort of manual. The length still equals this. So this gets entered and then you notice the variance. Okay. Let's look at these mental values of IP address using IP address that has a name list your else have IP address. So now let's see the same thing using abnormal URL. So in abnormal URL, so in case of abnormal URL, the D-Facement URL have higher distribution. Right? The count of D-Facement is quite high. And let's also see maybe suspicious URL. I'm just finding the count of suspicious URLs. Here, we can see it's clear that the benign URLs have the highest distribution while phishing URLs have a second highest distribution. Because as suspicious URLs are like contain transaction payment-related keywords. And generally, G9 or original banking or payment-related URLs conceses these words. So that's why benign URLs have the highest distribution. So here I can just let's see one more maybe. A distribution of count of dot. So I said that for suspicious emails, the number of dots will be very high. Okay, here it's not indicating that. That's fine. All right. So from media, I'm just extracting some insights, getting to know which URLs I suspicious or good emails. Okay, so this is my data. Now I'll be label encoding because label encoding is one of the important stuff because your machine won't understand words. It'll only understand numbers. So we have to import this type column using label encoding because it'll encode the target variable. So it can be converted into a numerical category. So phishing will be converted as zero benign one, basement two, and the four type as three. I'll just encode this variable. Because they'll only understand machine learning algorithms only understand numerical variables. So label encoding what it does is it'll encode. So we have four types right benign, decasement, malware, unsuspecies. So where our benign is there, it'll be replaced by zero, where our decasement is there, it'll be replaced by one, where our malware is there by two, where our suspicious categories are it'll be replaced by three. So label encoding does that. So let's apply label encoding. So applying label encoding and I'm creating a new column for a stable type code which is the label encoder, the type target. So if I check the head, for this is the type which is having category building time and at last, I have this type code which is nothing but the encode of that column. The next step is where we should segregate or create features and target variables. So we have created a predictor under target variable. So I exist your predictors and why is your target variable which is type code. So it contains all your input features which we have extracted from the lexical functions. Then drain test plate. So in this step, we'll split the data set into train and test. We have split the data set into 80s to 20 ratio. That means 80% of the data will be used for training the model and the 20% will be used to test the model. Okay. Now let's see model building. So in this step, we'll be building three based machine learning models. So first we'll start off with random polish classifier. So this core is for building machine learning models. So as I said, in train test plate, I have split this two variables. Let me just give you the overview. See, in right now, I just have one single data frame. I had one single data frame which contains independent or the predictors and the target Y. So what we did, we just split this data frame into two parts. 80% of the data for testing and 20% of the data for training. So this is extreme white train. This is x test. This is y test. So split the data after that. What we do is we'll use this extreme and white train to train my machine learning model because we know your machine learning is dependent on data and we'll use this testing data set to evaluate my model. So what I'll do, this white test is the actual answer. This is the actual answer. So I'll pass this x test, your machine learning trained machine learning model, your machine learning will do some prediction. I'll store it as white bread. Then I'll compare. So this white bread is the prediction from the model. So you have the actual data white test and the prediction white bread. So I'll just compare by test and by prediction to know what is the performance of your machine learning model. So that's what we're going to try here. So building a random first classifier importing the module from a scalar library, then creating instance of that. So here I'm just using 100 estimators and rf.fit. This will train the model. rf.fit. I'll make the prediction for x test, storing that in y prediction. Then I'm just calculating the accuracy score. This might take a while. Let's wait for a minute. So this is the first model I'm trying, random first classifier, then I'll once I'm trying, it removes classic higher. So based on the result, we'll select which is the optimal model for the prediction of URLs. So after fitting the module, we have made the prediction on the test data, we have made the prediction on the test data. Then we got an accuracy of prediction of 96.1%. Then if I look at the feature importance, you're saying that the top five features which are impacting the law, it is post name length, count of direct trees, count of wild white web, abnormal URL and URL length. So these are the important features. Then we can also implementing an xgb-claspire, so importing xgb, xgb-claspire, fitting the model and prediction. And this second xgb model is having an accuracy of 95%. So from the above result, it is evident that the random forest is shows the best performance in terms of test accuracy, and it is attaining the highest accuracy of 96.6% with higher detection rate of benign. So based on the performance, we will select random forest for our model of our URL detection. So coming to the model prediction, so in this final step, we will predict the malicious URLs, that means we'll be extracting the features from the URL based on the extracted features, we will predict if it is malicious or not. So this is the code. Here we have a function for what has been which takes one argument called as URL. So we'll pass our URL into this function, and we have a list called as status inside this list and append all the lexical features. So first, status is the list. I'm appending whether it's having IP address or not. I'm appending abnormal URL or not, count of dot, count of www. So basically, I'm appending all the lexical features and I have discussed before. Then I'm just returning that list. Now, so this is a function to get the prediction from. So this is the test URL I'm passing, and features, feature test. So this contains all the lexical features. So main is a function. This is the main function, which I'll pass the URL. And this function returns all the features and it will store in features test. And I'm just converting into a 2D array because your circuit learned meets the data in a 2D array. Then if the prediction is zero, I'm going to return share. If the prediction is one, I'm going to return a replacement. If the prediction is two-fishing, if the prediction is three, malware. So let's see some examples. So I just created two functions. So here, I just have to urns. First one. So, tight turn. Okay, tight turn is a company, but after that, um, corporate.com.com. It doesn't look a g9, but the second one in if you get pdr.org, not the kita. So this looks g9. We'll see what your model says. The model is saying the first one is a malware. Second one, it's a save website or face. Save URL. Let's try it for spaceroot.com. So we know spaceroot.com is save. So your model is always printing the same thing. GovL.com. It is also save. So model is working properly. Then sub-tip2easeker.com. So this sounds malicious. Yeah, it is a malware. So we have demonstrated our machine learning approach to detect malware urns. So we have created almost 20 lexical features from the raw urns and trained machine learning models, exgeboost and random forest. Then after that, we have performed. We have compared the pokomins of the machine learning models and found that random forest was the best. Then we just used a couple of top features for classifying malicious or sale. Then at last, we have code in the prediction function for classifying raw urns using random forest. So that's all for this CDU. This was a full demonstration. Yeah, so that's how you detect malware urns. Thank you.