 Hello everyone. So now let's study second methodology footprinting through web services. So here let's see how footprinting can be conducted through web services. So let me take a real time example. So web service right, services offering through web. Let's take an example of make my trip. If you want to book a flight right. So at our place, setting somewhere remotely, any individual can book a flight ticket right. Yeah. So, same way, how he tries to conduct footprinting through web services. So why he used to conduct in the sense, he can drag so many target companies, top level demands, sub domains. Okay. So example dot com, it's nothing but our domain name. In that dot com dot org dot in these are all that top level domains. Okay. So example as nothing but a second level domain. Okay. Before example, there will be a HTTP, HTTP, okay, drone, then we have a second level domain. So in that way, in footprinting through web services, he tries to fetch, you know, top level domains, sub domains, even he focuses on location. He tries to gather information as much as possible from the job sites also, even he focuses on determining OS. Let's go with the third methodology, footprinting through social networking sites here. Okay. So as you know, social networking sites, the example for social networks sites, right, we have we use Facebook, Twitter, LinkedIn, right. These all come under social networking sites, right. So attacker, he tries to use social engineering to care to gather sensitive information from social networking sites. Okay. It may be our Twitter, LinkedIn, Facebook, anything, maybe. So attacker is to create a fake profile on social networking sites and they used to use, you know, they're going to use all false identity, you know, to lure the employees and to give up their sensitive information here. Okay. So sometimes he may create a fake ID generator. He may use fake ID generator and he may, you know, enhance identity theft and sometimes he tries to drag all that sensitive information from a victim. So example, I would tell you, employees, they may post some personal information such as data of birth, educational and employment background, you know, sometimes post name, fianceing, right. All the respective information about their company, okay. Each and every thing we can see, right. He may post anything on the social networking site. So attacker used to collect these information about employee interest, okay. And they select the target and finally, they trick these employees to reveal more information. So we can see here, what all the information used to available on social networking sites, all the things that friend list contact information location, interest, activities, right. So these are the nothing but information that available on social networking sites. Yes, let's focus on website footprinting here. So yes, website footprinting, it refers to monitoring and analysis of target organization website. Very focus of all monitoring as well as he tries to analyze the organization website. He tries to check their sub-directories, scripting platforms, software, what software they're going to use. See, weaponizer, we have a tool here, right. So this is the weaponizer tool where he tries to identify the technologies used by them, okay, under the website. So website informer is also one of the best tool, let me help you here. Yes, so this comes under website footprinting tools. So we have a weaponizer and website informer. In order to fetch a complete information on some, you know, complete information about that website. So we're going to get it that from website informer if he wants to identify the technologies which they have been used in building those website, okay, we can go with the weaponizer. We can just check how many technologies have been involved in building the website. And this weaponizer tool, all of the best website for printing tools they have. So we have website monitoring tool also, one of the best website monitoring tool is HISTING TRACK website copyer. We also have black widow. So even sometimes he uses burpsuit zap proxy website informer. So these tools in order to fetch the web server which are in use their version. Last modified information, everything can be fetched even they sometimes examine cookies. Also by examine cookies. So they try to fetch software which is in use and their behavior, okay, and they also focus on scripting platform which is being used there, okay. So overall I would like to tell you even website footprinting can be used, you know, they sometimes use the web spider's also, okay. Let me tell you about the website is here. So websites are the one who used to perform automated searches, automated searches on the target website. And they used to collect a specific information about employing memes, email IDs, okay. Also attacker uses these, you know, the collected information to perform further footprinting and social engineering attacks, okay. So one of the tools as a web spider we can use a web data extractor and we also have GSE emails spider. So sometimes he even tries to mirror a website entire website he tries to mirror on the local system and whatever this mirroring it completely enables an attacker to browse website offline, okay. Sometimes this tool which I referred as HT track website copier, HT track website copier, one of the best engineering tool, website engineering tool. So these tools it also assists in finding directory structure. That means we'll be fetching out all the valuable information from the mirrored copy, okay. So these tools used to allow our respective attacker to download a website to local directory here, okay. So yes, one of the best tool and we also have a mirroring tool as surf online, okay. So these are the respective the methodology of that needs the website footprinting methodology let's focus on tracking email communication. Let's say what is the next methodology here? Yes, I would like to also tell you about a deep web dark web before going to other methodology. So yes, can I show you this here? We have three categories and a worldwide web. We have surface web deep web dark web here, okay. So as we can see in a surface web it comes a Google, Facebook, Yahoo Wikipedia, anything let's follow like you know general users, right. Under surface web all your Instagram, Facebook, Qtob, anything, yeah. So generally it's a portion of worldwide web which is readily available to the general public here, right. With standard web search engines. How about our deep web, the second portion, okay. So we also have a deep web here. It's nothing but you know where we use if you want to get into our you know if you want to get into our admin panel, we need some specialized URLs. We need some sign in credentials. That means I would like to give you an example on deep web, okay. So if I am working under CID department. Yes, if I enter in a Google anywhere I can't get there you know specific or specified or special URLs, right. Because it's associated with them, right. If I enter in a Google like I want to fetch some you know CID department personal link, I can't get into that, right. So if CID department had if he provides me that special link then I can get into that and panel by you know by validating my authorization then. So same way the main difference between the surface web and the deep web is here everything is being indexed, okay. So the main difference is if surface web it is completely visible to an you know it is completely accessible. Anybody can access anything from that. Okay. And here when it comes to when it comes to a deep web here all your private networks, medical records, yeah you can see everything comes up here in the deep web, okay. Even deep web is the invisible web you can say a hidden web, okay. So where all you know your contents are not indexed here, okay. Getting it. So yes accessing this dark web is even it's illegal here, okay. So we have surface web deep web dark web. So with a clear explanation I would like to say surface web generally you can access anything like Facebook you know Wikipedia, Google, YouTube, everything. And then this all comes in the surface web deep web if it comes to deep web all the respective hidden files hidden URLs like you know specialized URLs with respect to some organizations, okay. So private forums, net banking part related to some banks. So these comes under this part, okay. So deep web is a sub dark web is a subset of deep web, okay. And when all your luck you know some people if they want to export import drugs, if they want to conduct a malicious activities, fraudulent activities, if they want to surf anything unanimously they go with dark web. Dark web is nothing but you know even you can buy an unlicensed gun there. All the malicious activities used to happen there, okay. So what attackers use is store browser. This web deep web here we can easily use Chrome browser and we can you know check our net banking part, we can research with the specialized URLs with the proper authorization, yeah even I can check our medical record, right. But in the dark web, so if he attackers use to use this dark web in order to conduct all the malicious activities and even they use this dark web to surf unanimously, okay. Why they use store browser under the dark web because there is an onion router. The mechanism, the agenda we have, there is onion router where the IP ranges, you know, IP used to randomly change there, okay. So what we have a special onion router under top browser. So always surface web deep web can be we can easily enhance Chrome browsers or any kind of browsers there. So when we come to dark web we just attackers, they just focus on store browser, okay. So yeah we have a web at machine tool also. It's nothing but now it's a digital chip where we can search the hidden things, hidden files and you can just check how the websites have been upgraded, how they have been updated each and everything in this tool, okay. So this is nothing but a digital archiv of the worldwide web founded by a different archiv, okay. So this has been founded by some American organization and nonprofit one. So it's based in San Francisco, California. This tool has been created in 1996 but they launched during 2001. So it is the tool which allows the user to go back in time to see how websites looked in the past. Yes. So we have a different next methodology, a different one, a network footprinting. So it is also one of the important footprinting methodology where attackers use to focus on all the range of IP addresses. So he tries to check this subnet pass, subnet mask. He tries to check the range of IP addresses and this subnet mask here, okay. And we have tools for that. We will be using path analyzer pro trace root tool. We have a Windows utility command, a trace art to trace the root of the packets. Using these tools we can easily describe that, you know, easily attacker can map the whole network infrastructure here, okay. So overall in this network footprinting attacker tries to locate the network range. Let me just show you here one moment. So we have a network footprinting here. So here a network range information he tries to extract and these further assets attacker, okay. This is going to the information assist attacker in order to create a map of the target network. Okay. So main thing is under this network footprinting he tries to find the range of IP addresses. Okay. So here you can find the range of IP addresses. You can check there is subnet mask also. Subnet mask it's nothing but a process where IP addresses will be separated into host address as well as the network address, okay. So what is the range actually? Attackers usually they try to find the range of IP addresses and this subnet mask used by the target organization here, okay. So regional internet registry, RIR, okay. So as I told you I would like to tell you about raise root. When it comes to networking we need to focus on the raise root also. Raise root programs they completely work on the concept of this ICMP protocol, okay. So in under your command, under your command prompt, if we use pink command we can check whether host is alive or dead, yeah. Even if you want to raise the root of the packets we can use this result command if you want IPv4, IPv6, IPv6 and the respective domain name, okay. So we can check here using this raise root technique, yeah. So attackers they conduct this raise reward analysis in order to extract information about network topology, trusted rooters and also they try to extract firewall locations. Let me quickly show you this here. Yes. So we're including how raise root happens here, okay. So there we, these are the very important technique, raise root analysis which happens under them network for printing here.